"""
Example: Basic log analysis workflow

Demonstrates LogGem's core features with multiple model options including
lightweight models like Gemma 3 4B, Gemma 3 12B, and Gemma 3 27B.
"""

from pathlib import Path
from loggem.parsers import LogParserFactory
from loggem.detector import AnomalyDetector
from loggem.analyzer import LogAnalyzer, PatternDetector


def print_banner():
    """Print example banner."""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  LogGem Basic Usage Example                              â•‘
â•‘  AI-Powered Log Analysis with Lightweight Models         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)


def demo_rule_based_detection():
    """Demonstrate fast rule-based detection."""
    print("\n" + "="*60)
    print("  ğŸ” RULE-BASED DETECTION (No AI - Instant Results)")
    print("="*60)
    
    # 1. Parse logs
    print("\nğŸ“‹ Parsing auth logs...")
    parser = LogParserFactory.create_parser(
        format_type="auth",
        file_path=Path("examples/sample_auth.log")
    )
    entries = list(parser.parse_file(Path("examples/sample_auth.log")))
    print(f"âœ… Parsed {len(entries)} log entries")
    
    # 2. Rule-based detection (fast, no model needed)
    print("\nï¿½ Running rule-based pattern detection...")
    pattern_detector = PatternDetector()
    rule_anomalies = pattern_detector.detect_all(entries)
    print(f"âœ… Found {len(rule_anomalies)} anomalies via rules")
    
    # 3. Analyze results
    print("\nğŸ“Š Analyzing results...")
    analyzer = LogAnalyzer()
    result = analyzer.analyze(entries, rule_anomalies)
    
    # 4. Display results
    print(f"\n{'='*60}")
    print("  ğŸ“ˆ ANALYSIS RESULTS")
    print(f"{'='*60}")
    print(f"Total entries:     {result.total_entries}")
    print(f"Anomalies found:   {len(result.anomalies)}")
    print(f"Analysis duration: {result.duration:.2f}s")
    
    if result.anomalies:
        print(f"\n{'='*60}")
        print("  ğŸš¨ TOP ANOMALIES")
        print(f"{'='*60}")
        for i, anomaly in enumerate(result.anomalies[:5], 1):
            severity_emoji = {
                "CRITICAL": "ğŸ”´",
                "HIGH": "ğŸŸ ", 
                "MEDIUM": "ğŸŸ¡",
                "LOW": "ğŸŸ¢"
            }.get(anomaly.severity.value, "âšª")
            
            print(f"\n{i}. {severity_emoji} [{anomaly.severity.value}] {anomaly.anomaly_type.value}")
            print(f"   Confidence:  {anomaly.confidence:.1%}")
            print(f"   Description: {anomaly.description}")
            if anomaly.recommendation:
                print(f"   ğŸ’¡ {anomaly.recommendation}")
    
    print(f"\n{'='*60}")
    print("  ğŸ“Š PATTERNS DETECTED")
    print(f"{'='*60}")
    for pattern, count in result.patterns.items():
        print(f"  â€¢ {pattern}: {count}")


def demo_ai_detection_gemma_2b():
    """Demonstrate AI detection with Gemma 3 4B (default, fast)."""
    print("\n\n" + "="*60)
    print("  ğŸ¤– AI DETECTION - Gemma 3 4B (Fast & Efficient)")
    print("="*60)
    print("\nâš™ï¸  Model: google/gemma-3-4b-it")
    print("ğŸ’¾ Size:  ~4GB download (first run only)")
    print("ğŸ§  RAM:   8GB required")
    print("âš¡ Speed: ~1-2s per log entry")
    print("\nğŸ’¡ This is the default model - best for most users!")
    
    # Uncomment to enable AI detection:
    """
    from loggem.detector.model_manager import ModelManager
    
    # Initialize with Gemma 3 4B (default)
    print("\nğŸ“¥ Loading Gemma 3 4B model...")
    manager = ModelManager(
        provider_type="huggingface",
        provider_config={
            "model_name": "google/gemma-3-4b-it",
            "device": "auto",  # Uses GPU if available
            "quantization": "int8",  # 4x smaller, minimal accuracy loss
        }
    )
    manager.load_model()
    
    # Parse and detect
    parser = LogParserFactory.create_parser("auth")
    entries = list(parser.parse_file(Path("examples/sample_auth.log")))[:10]
    
    print(f"ğŸ” Analyzing {len(entries)} entries with AI...")
    detector = AnomalyDetector()
    anomalies = []
    
    for i, entry in enumerate(entries, 1):
        print(f"  Processing {i}/{len(entries)}...", end="\\r")
        anomaly = detector.detect(entry)
        if anomaly:
            anomalies.append(anomaly)
    
    print(f"\\nâœ… Found {len(anomalies)} AI-detected anomalies")
    """
    
    print("\nâš ï¸  AI detection commented out in example")
    print("   Uncomment code above to enable (requires model download)")


def demo_model_comparison():
    """Show comparison of different Gemma models."""
    print("\n\n" + "="*60)
    print("  ğŸ“Š MODEL COMPARISON")
    print("="*60)
    print("""
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  Model          â”‚ Download â”‚  RAM  â”‚ Speed    â”‚ Accuracy â”‚ Use Case  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Gemma 3 4B-it  â”‚  ~4GB    â”‚  8GB  â”‚ âš¡âš¡âš¡     â”‚ â­â­â­     â”‚ Default   â”‚
â”‚                 â”‚          â”‚       â”‚          â”‚          â”‚ Fast      â”‚
â”‚                 â”‚          â”‚       â”‚          â”‚          â”‚ Efficient â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Gemma 3 12B-it  â”‚  ~12GB    â”‚ 16GB  â”‚ âš¡âš¡       â”‚ â­â­â­â­    â”‚ Balanced  â”‚
â”‚                 â”‚          â”‚       â”‚          â”‚          â”‚ Better    â”‚
â”‚                 â”‚          â”‚       â”‚          â”‚          â”‚ Accuracy  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Gemma 3 27B-it â”‚  ~27GB   â”‚ 34GB  â”‚ âš¡        â”‚ â­â­â­â­â­   â”‚ Best      â”‚
â”‚                 â”‚          â”‚       â”‚          â”‚          â”‚ Highest   â”‚
â”‚                 â”‚          â”‚       â”‚          â”‚          â”‚ Quality   â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

ğŸ’¡ How to use different models:
""")
    
    print("\n1ï¸âƒ£  Gemma 3 4B (Default) - config.yaml:")
    print("""
    model:
      provider: "huggingface"
      name: "google/gemma-3-4b-it"
      device: "auto"
      quantization: "int8"
    """)
    
    print("\n2ï¸âƒ£  Gemma 3 12B (Better) - config.yaml:")
    print("""
    model:
      provider: "huggingface"
      name: "google/gemma-3-12b-it"
      device: "auto"
      quantization: "int8"
    """)
    
    print("\n3ï¸âƒ£  Gemma 3 27B (Best) - config.yaml:")
    print("""
    model:
      provider: "huggingface"
      name: "google/gemma-3-27b-it"
      device: "auto"
      quantization: "int8"
    """)
    
    print("\n4ï¸âƒ£  Alternative Models:")
    print("""
    # Llama 3.2 3B (Fast alternative)
    name: "meta-llama/Llama-3.2-3B-Instruct"
    
    # Mistral 7B (Balanced)
    name: "mistralai/Mistral-7B-Instruct-v0.3"
    
    # Qwen 2.5 7B (Good multilingual)
    name: "Qwen/Qwen2.5-7B-Instruct"
    """)


def main():
    """Run all demonstrations."""
    print_banner()
    
    print("""
This example demonstrates LogGem's capabilities:
  â€¢ Rule-based detection (instant, no AI)
  â€¢ AI detection with Gemma 3 models
  â€¢ Model comparison and selection

Choose the right model for your needs:
  â€¢ Gemma 3 4B:  Fast, 8GB RAM  â† Start here!
  â€¢ Gemma 3 12B:  Better, 16GB RAM
  â€¢ Gemma 3 27B: Best, 34GB RAM
""")
    
    # Demo 1: Fast rule-based detection
    demo_rule_based_detection()
    
    # Demo 2: AI detection with Gemma 3B
    demo_ai_detection_gemma_2b()
    
    # Demo 3: Model comparison
    demo_model_comparison()
    
    print("\n\n" + "="*60)
    print("  âœ… EXAMPLE COMPLETE")
    print("="*60)
    print("""
ğŸ“š Next Steps:
  1. Try enabling AI detection (uncomment code above)
  2. Experiment with different models in config.yaml
  3. Check examples/custom_parser.py for custom formats
  4. Read EXAMPLES.md for more advanced usage

ğŸ’ LogGem - Intelligent log analysis with lightweight LLMs!
    """)


if __name__ == "__main__":
    main()
